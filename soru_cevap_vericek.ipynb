{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doktorlar_detay = pd.read_csv('doktorlar_detay.csv')\n",
    "doktorlar_detay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = doktorlar_detay['data_id'].dropna().astype(int).to_list()\n",
    "len(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# https://api.doktorsitesi.com/public/question-thread/profile/180089?page=1&limit=100000\n",
    "\n",
    "# the response is a json object\n",
    "\n",
    "zero_responses = []\n",
    "error_data_ids = []\n",
    "\n",
    "start_time = time.time()\n",
    "async def fetch(session, url, data_id):\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            res = await response.json()\n",
    "            # {\"count\": \"0\", \"items\": []}\n",
    "            # save the response to a json file with the name of the data_id in the soru_cevap folder\n",
    "            if res['count'] == '0':\n",
    "                zero_responses.append(data_id)\n",
    "                print(f\"{url} has no response\")\n",
    "            else:\n",
    "                with open(f'soru_cevap/{data_id}.json', 'w') as f:\n",
    "                    json.dump(res, f, ensure_ascii=False)\n",
    "            \n",
    "                print(f\"{url} is fetched\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured while fetching {url}\")\n",
    "        print(e)\n",
    "        error_data_ids.append(data_id)\n",
    "async def fetch_all(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i, url in enumerate(urls):\n",
    "            task = asyncio.create_task(fetch(session, url, data_id[i]))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "    \n",
    "urls = [f'https://api.doktorsitesi.com/public/question-thread/profile/{data_id[i]}?page=1&limit=1000000' for i in range(len(data_id))]\n",
    "await fetch_all(urls)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zero_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add response count to the doktorlar_detay dataframe and save it to a csv file\n",
    "\n",
    "for di in data_id:\n",
    "    try:\n",
    "        with open(f'soru_cevap/{di}.json') as f:\n",
    "            res = json.load(f)\n",
    "            doktorlar_detay.loc[doktorlar_detay['data_id'] == di, 'response_count'] = res['count']\n",
    "    except:\n",
    "        doktorlar_detay.loc[doktorlar_detay['data_id'] == di, 'response_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doktorlar_detay.to_csv('doktorlar_detay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doktorlar_detay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total response count\n",
    "\n",
    "total_response_count = 0\n",
    "for di in data_id:\n",
    "    try:\n",
    "        with open(f'soru_cevap/{di}.json') as f:\n",
    "            res = json.load(f)\n",
    "            total_response_count += int(res['count'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "total_response_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data_id to int if it is not already int or not nan\n",
    "doktorlar_detay['data_id'] = doktorlar_detay['data_id'].apply(lambda x: int(x) if not pd.isna(x) else x)\n",
    "\n",
    "# save it to a csv file\n",
    "doktorlar_detay.to_csv('doktorlar_detay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doktorlar_detay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 167.852 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
